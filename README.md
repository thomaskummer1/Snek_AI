# Snek_AI
Video Link: https://youtu.be/SKw1DESS3IA 
Write Up, Group: Thomas Kummer, Willem Shak

The project we were trying to solve in this project was to create an AI model that learns to play the simple game Snake.  This may seem like a small game with no other applications, but creating an AI that can learn to traverse a terain to reach a certain goal is very useful for the future of AI.  It can be used in games to train AI to walk like real people or in robots to allow them to traverse real life warehouses.  The source of data for this project was our own.  We created a snake game that draws the snake and a random food location and then moves the snake in the inputed direction until a collision with itself or the wall occurs.  Colliding with the food also makes the snake grow and randomly places another food.  This is the source of our data as the neural network began with no data and made its moves virtually randomly.  This would be the first point of improvement if we continued on in the future as the random start can cause random behaviors to continue in future generations.  Since we used a genetic algorithm to bread the top performers in each generation, if the top performers all exhibit some similar trait that trait will continue in the future generations whether it's good or not.  In our example our snake would correctly seek out and move towards the food, but before it did that it would always move to the left wall.  This means that at some point the top performers would move to the left wall and this trait was continued in the children and the best performers would then always calibrate at the left wall.  Another point that we could've improved upon given more time is the variables we passed into the neural network.  We passed in the food direction, snake direction, and if any adjesent moves were blocked, which was enough for the snake to learn how to eat some food and avoid most barriers, but there is much more data on the board than just that.  If we inputed an entire game state the snake would be able to learn much quicker on the best way to reach the food, however this would take a lot more processing power and intern would cause the snakes to run much slower and each generation would take exponentially longer than it does now.  Finding a middle ground between the data we've inputed and the entire board would take a while, but it could greatly improve the speed at which the AI learns to play the game.  The best thing we've learned from this experiment is how neural networks and genetic algorithms work together due to us implementing them by hand rather than using a library.  Our neural network learns from each neuron inputed and figures out the best way to combine each variable stated earlier to pick the best move to survive and get closer to the food.  Our genetic algorithm finds the best performers from each generation and breeds them together to hopefully get the best traits from each.  This allows our best performers to mutate by combining with one another, and then taking the best of those mutations to combine with one another.  We didn't split up the work and instead opted to code together.  Since one of us was on the West Coast and the other the East Coast we created calls and one of us would share our screen and code while the other would assist.  This lead to us both completing a majority of the project and helping the other through bugs and errors.
